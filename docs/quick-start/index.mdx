---
id: quick-start
title: Quick Start
description: Quick and easy steps to get started using Crawlee today!
---

import ApiLink from '@site/src/components/ApiLink';

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

import CheerioSource from '!!raw-loader!./quick_start_cheerio.ts';
import PlaywrightSource from '!!raw-loader!./quick_start_playwright.ts';
import PuppeteerSource from '!!raw-loader!./quick_start_puppeteer.ts';

import CheerioLog from '!!raw-loader!./quick_start_cheerio.txt';

With this short tutorial you can start scraping with Crawlee in a minute or two. To learn in-depth how Crawlee works, read the [Introduction](./introduction), which is a comprehensive step-by-step guide for creating your first scraper.

## Choose your crawler

Crawlee comes with three different crawler classes: <ApiLink to="cheerio-crawler/class/CheerioCrawler">`CheerioCrawler`</ApiLink>, <ApiLink to="puppeteer-crawler/class/PuppeteerCrawler">`PuppeteerCrawler`</ApiLink> and <ApiLink to="playwright-crawler/class/PlaywrightCrawler">`PlaywrightCrawler`</ApiLink>. All classes share the same interface for maximum flexibility when switching between them.

### CheerioCrawler
This is a plain HTTP crawler. It parses HTML using the [Cheerio](https://github.com/cheeriojs/cheerio) library and crawls the web using the specialized [got-scraping](https://github.com/apify/got-scraping) HTTP client which masks as a browser. It's very fast and efficient, but can't handle JavaScript rendering.

### PuppeteerCrawler
This crawler uses a headless browser to crawl, controlled by the [Puppeteer](https://github.com/puppeteer/puppeteer) library. It can control Chromium or Chrome. Puppeteer is the de-facto standard in headless browser automation.

### PlaywrightCrawler
[Playwright](https://github.com/microsoft/playwright) is a more powerful and full-featured successor to Puppeteer. It can control Chromium, Chrome, Firefox, Webkit and many other browsers. If you're not familiar with Puppeteer already, and you need a headless browser, go with Playwright.

## Installation

Crawlee requires [Node.js](https://nodejs.org/en/) 16 or later.
It can be added to any Node.js project by running:

<Tabs groupId="quick_start">
<TabItem value="cheerio" label="CheerioCrawler" default>
<CodeBlock language="bash">npm install crawlee</CodeBlock>
</TabItem>
<TabItem value="playwright" label="PlaywrightCrawler">
<CodeBlock language="bash">npm install crawlee playwright</CodeBlock>

:::caution

`playwright` is not bundled with Crawlee to reduce install size and allow greater flexibility. You need to explicitly install it with NPM.

:::

</TabItem>
<TabItem value="puppeteer" label="PuppeteerCrawler">
<CodeBlock language="bash">npm install crawlee puppeteer</CodeBlock>

:::caution

`puppeteer` is not bundled with Crawlee to reduce install size and allow greater flexibility. You need to explicitly install it with NPM.

:::

</TabItem>
</Tabs>

## Crawling

Run the following example to perform a recursive crawl of a website using:

<Tabs groupId="quick_start">
    <TabItem value="cheerio" label="CheerioCrawler" default>
        <CodeBlock language="js" title="src/main.mjs">{CheerioSource}</CodeBlock>
    </TabItem>
    <TabItem value="playwright" label="PlaywrightCrawler">
        <CodeBlock language="js" title="src/main.mjs">{PlaywrightSource}</CodeBlock>
    </TabItem>
    <TabItem value="puppeteer" label="PuppeteerCrawler">
        <CodeBlock language="js" title="src/main.mjs">{PuppeteerSource}</CodeBlock>
    </TabItem>
</Tabs>

When you run the example, you will see Crawlee automating the data extraction process.

<Tabs groupId="quick_start">
<TabItem value="cheerio" label="CheerioCrawler" default>
Logs in your terminal will show the progress of your scraping:
<CodeBlock language="log">{CheerioLog}</CodeBlock>
</TabItem>
<TabItem value="playwright" label="PlaywrightCrawler">
Logs in your terminal will show the progress of your scraping and you will also see Crawlee automating a browser:

![Chrome Scrape](/img/chrome_scrape.gif)

</TabItem>
<TabItem value="puppeteer" label="PuppeteerCrawler">
Logs in your terminal will show the progress of your scraping and you will also see Crawlee automating a browser:

![Chrome Scrape](/img/chrome_scrape.gif)

</TabItem>
</Tabs>

:::tip

Crawlee stores data to `./storage` in the current working directory. The results of your crawl will be available under `./storage/datasets/default/*`. You can override this behavior by setting the `CRAWLEE_STORAGE_DIR` environment variable.

:::

More examples showcasing various features of Crawlee could be found in [Examples](./examples) section of the documentation.

**Related links**

- [Environment variables](./guides/environment-variables)
- [Request storage](./guides/request-storage)
- [Result storage](./guides/result-storage)

## Local usage with Crawlee command-line interface (CLI)

To create a boilerplate of your project, you can use the [Crawlee CLI](https://www.npmjs.com/package/@crawlee/cli) tool by running:

```bash
npx crawlee create my-cheerio-crawler
```

The CLI will prompt you to select a project boilerplate template - let's pick the **Crawlee cheerio template [TypeScript]**. The tool will create a directory called `my-cheerio-crawler` with Node.js project files. You can run the project as follows:

```bash
cd my-cheerio-crawler
npm start
```
